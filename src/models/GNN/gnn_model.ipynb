{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "from gnn_utils import trainGCN, FileRiboDataset # custom dataset and trainer\n",
    "import random\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch_geometric\n",
    "import torch_geometric.transforms as T\n",
    "from torch import nn\n",
    "from torchmetrics.functional import pearson_corrcoef\n",
    "from torchmetrics import Metric\n",
    "import argparse\n",
    "from sklearn.model_selection import KFold\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import pytorch_lightning as pl\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_attr = 'None' # 'Yes' (default, will send the 2 features), 'None' (will make then None), 'Zero' (will convert them to zeros)\n",
    "\n",
    "loss_fn = 'MAE + PCC'\n",
    "features = ['embedding']\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--random_walk', type=bool, default=True, help='addition of random walk embedding')\n",
    "parser.add_argument('--model_algo', type=str, default='GCN_LSTM', help='model algorithm') # GCN_LSTM, GCNOnly, LSTMEmbedswGCN\n",
    "parser.add_argument('--gcn_layers', type=str, default='[256, 128, 128, 64]', help='gcn layers and nodes') #\n",
    "parser.add_argument('--batch_size', type=int, default=1, help='model training batch size') # \n",
    "parser.add_argument('--lr', type=float, default=1e-3, help='learning rate of the model') # \n",
    "parser.add_argument('--algo', type=str, default='SAGE', help='convolution algorithm') # SAGE, GAT, GATv2, GINE, TF, DeepGCN (which uses TF)\n",
    "parser.add_argument('--cheb_k', type=int, default=2, help='chebyshev filter K size') # SAGE, GAT, GATv2, GINE, TF, DeepGCN (which uses TF)\n",
    "parser.add_argument('--dropout', type=float, default=0.1, help='dropout value') # additional rna folding features with the category of the nts\n",
    "parser.add_argument('--seed', type=int, default=42, help='seed value') # random seed initialization\n",
    "args = parser.parse_args()\n",
    "\n",
    "# reproducibility\n",
    "pl.seed_everything(args.seed)\n",
    "\n",
    "random_walk = args.random_walk # True or False\n",
    "model_algo = args.model_algo # GCNOnly, GCN_LSTM, Ensemble\n",
    "\n",
    "if 'x' in args.gcn_layers:\n",
    "    gcn_layers_strip = args.gcn_layers.strip('[]').split(', ')\n",
    "    gcn_layers = []\n",
    "    for i in gcn_layers_strip:\n",
    "        if 'x' in i:\n",
    "            gcn_layers += [int(i.split('x')[0])]*int(i.split('x')[1])\n",
    "        else:\n",
    "            gcn_layers += [int(i)]\n",
    "else:\n",
    "    gcn_layers = [int(i) for i in args.gcn_layers.strip('[]').split(', ')]\n",
    "\n",
    "cheb_k = args.cheb_k\n",
    "algo = args.algo \n",
    "\n",
    "# training arguments\n",
    "tot_epochs = 200\n",
    "batch_size = args.batch_size\n",
    "dropout_val = args.dropout\n",
    "annot_thresh = 0.3\n",
    "longZerosThresh_val = 20\n",
    "percNansThresh_val = 0.05\n",
    "random_walk_length = 32\n",
    "alpha = -1\n",
    "lr = args.lr\n",
    "\n",
    "proc_data_folder = 'LiverGraphs/'\n",
    "\n",
    "features_str = '_'.join(features)\n",
    "\n",
    "model_name = str(model_algo) + '-' + algo + '[BS ' + str(batch_size) + ', D ' + str(dropout_val) + ', E ' + str(tot_epochs) + ', LR ' + str(lr) + ', RW ' + str(random_walk) + ', CK: ' + str(cheb_k) + ', Seed: ' + str(args.seed) +  ']' + 'L: ' + str(args.gcn_layers)\n",
    "\n",
    "input_nums_dict = {'embedding': gcn_layers[0]}\n",
    "num_inp_ft = sum([input_nums_dict[ft] for ft in features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start a new wandb run to track this script\n",
    "wandb_logger = WandbLogger(log_model=\"all\", project=\"GCN_MM\", name=model_name)\n",
    "\n",
    "# model parameters\n",
    "save_loc = 'saved_models/' + model_name\n",
    "\n",
    "train_ds = FileRiboDataset(proc_data_folder, 'train', edge_attr, shuffle=True, random_walk=random_walk)\n",
    "test_ds = FileRiboDataset(proc_data_folder, 'test', edge_attr, shuffle=False, random_walk=random_walk)\n",
    "\n",
    "print(\"samples in train dataset: \", len(train_ds))\n",
    "print(\"samples in test dataset: \", len(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "model, result = trainGCN(gcn_layers, tot_epochs, batch_size, lr, save_loc, wandb_logger, train_ds, test_ds, dropout_val, num_inp_ft, algo, edge_attr, random_walk, model_algo, cheb_k)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
