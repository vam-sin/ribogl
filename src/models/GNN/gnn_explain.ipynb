{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "from torch_geometric.explain import Explainer, CaptumExplainer\n",
    "import torch_geometric.transforms as T\n",
    "import torch \n",
    "import captum\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gnn_explain_utils import GCN_LSTMNonEmbed, GCN_LSTM\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.backends.cudnn.enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a sample from the test folder\n",
    "feature_folder = 'LiverGraphs/test/'\n",
    "\n",
    "# load test file\n",
    "exp_dat = exp_dat = pd.read_csv('data/test.csv')\n",
    "\n",
    "# load the model\n",
    "tot_epochs = 50\n",
    "batch_size = 2\n",
    "dropout_val = 0.4\n",
    "annot_thresh = 0.3\n",
    "longZerosThresh_val = 20\n",
    "percNansThresh_val = 0.05\n",
    "random_walk_length = 32\n",
    "alpha = -1\n",
    "lr = 1e-3\n",
    "algo = 'SAGE'\n",
    "edge_attr = 'None'\n",
    "features = ['embedding']\n",
    "features_str = '_'.join(features)\n",
    "loss_fn = 'MAE + PCC'\n",
    "gcn_layers = [256, 128, 128, 64]\n",
    "input_nums_dict = {'embedding': 256}\n",
    "num_inp_ft = sum([input_nums_dict[ft] for ft in features])\n",
    "\n",
    "save_loc = 'saved_models/LSTM/best.ckpt'\n",
    "l_model = GCN_LSTM.load_from_checkpoint(save_loc, gcn_layers=gcn_layers, dropout_val=dropout_val, num_epochs=tot_epochs, bs=batch_size, lr=lr, num_inp_ft=num_inp_ft, alpha=alpha, algo=algo, edge_attr=edge_attr)\n",
    "\n",
    "# remove embeddings layer from the model\n",
    "non_embed_model = GCN_LSTMNonEmbed.load_from_checkpoint(save_loc, gcn_layers=gcn_layers, dropout_val=dropout_val, num_epochs=tot_epochs, bs=batch_size, lr=lr, num_inp_ft=num_inp_ft, algo=algo, edge_attr=edge_attr)\n",
    "\n",
    "explainer = Explainer(\n",
    "    model=non_embed_model, # get torch module from lightning module\n",
    "    algorithm=CaptumExplainer(attribution_method=captum.attr.InputXGradient),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='regression',\n",
    "        task_level='node',\n",
    "        return_type='raw',  # Model returns log probabilities.\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "part = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate explanation for the node at index `10`:\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "total_num_sample = len(list(exp_dat['transcript']))\n",
    "\n",
    "print(\"total samples: \", len(list(exp_dat['transcript'])))\n",
    "\n",
    "transcripts_list = list(exp_dat['transcript'])\n",
    "\n",
    "part_length = len(transcripts_list)\n",
    "\n",
    "out_folder_path = 'final_useqplus_int/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # explainability using captum\n",
    "# convert to tqdm for progress bar\n",
    "for sample_number in tqdm(range(part_length)):\n",
    "    # remove model eval\n",
    "\n",
    "    file_name = feature_folder + 'sample_' + str(sample_number) + '.pt'\n",
    "    \n",
    "    out_dict = {}\n",
    "    # load the sample\n",
    "    data = torch.load(file_name)\n",
    "    data.x = torch.tensor([int(k) for k in data.x['codon_seq']], dtype=torch.long)\n",
    "    data.y = data.y / torch.nansum(data.y)\n",
    "    data = data.to(device)\n",
    "    data.edge_attr = None\n",
    "\n",
    "    # get the embeddings\n",
    "    data.x = l_model.embedding(data.x)\n",
    "\n",
    "    data.x = torch.concat((data.x, data.random_walk_pe), dim=1)\n",
    "\n",
    "    # get the explanation\n",
    "    edge_explain_sample = []\n",
    "    node_explain_sample = []\n",
    "    \n",
    "    for index in tqdm(range(data.y.shape[0])):\n",
    "\n",
    "        explanation = explainer(x = data.x, edge_index = data.edge_index, index=index)\n",
    "        # add the edge_mask info to edge_index \n",
    "        edge_explain = torch.concat([data.edge_index, explanation.edge_mask.unsqueeze(dim=0)], dim=0)\n",
    "\n",
    "        # flatten edge_explain\n",
    "        edge_explain = edge_explain.view(-1)\n",
    "\n",
    "        edge_explain_sample.append(edge_explain)\n",
    "\n",
    "        node_explain = explanation.node_mask.sum(dim=1)\n",
    "\n",
    "        node_explain_sample.append(node_explain)\n",
    "\n",
    "    edge_explain_sample = torch.cat(edge_explain_sample, dim=0)\n",
    "    # convert to 1d\n",
    "    # edge_explain_sample = edge_explain_sample.view(-1)\n",
    "    node_explain_sample = torch.cat(node_explain_sample, dim=0)\n",
    "\n",
    "    # save the edge_explain_sample and node_explain_sample to the datasets\n",
    "    out_dict['node_attr_ds'] = node_explain_sample.detach().cpu().numpy()\n",
    "    out_dict['edge_attr_ds'] = edge_explain_sample.detach().cpu().numpy()\n",
    "\n",
    "    # # get the prediction\n",
    "    file_name = feature_folder + 'sample_' + str(sample_number) + '.pt'\n",
    "    # load the sample\n",
    "    data = torch.load(file_name)\n",
    "    data.edge_attr = None\n",
    "\n",
    "    # get the prediction\n",
    "    data.x = torch.tensor([int(k) for k in data.x['codon_seq']], dtype=torch.long)\n",
    "    data = data.to(device)\n",
    "    pred = l_model(data)\n",
    "\n",
    "    out_dict['y_pred'] = pred.detach().cpu().numpy()\n",
    "    out_dict['x_input'] = data.x.detach().cpu().numpy()\n",
    "    out_dict['edge_index'] = data.edge_index.detach().cpu().numpy()\n",
    "\n",
    "    # get the truth\n",
    "    data.y = data.y / torch.nansum(data.y)\n",
    "    truth = data.y\n",
    "\n",
    "    out_dict['y_true'] = truth.detach().cpu().numpy()\n",
    "\n",
    "    # add the transcript\n",
    "    out_dict['transcript'] = transcripts_list[sample_number]\n",
    "\n",
    "    # save out_dict\n",
    "    out_file_name = out_folder_path + 'sample_' + str(sample_number) + '.npz'\n",
    "    np.savez_compressed(out_file_name, out_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
