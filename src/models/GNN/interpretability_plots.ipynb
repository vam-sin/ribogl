{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/net/lts2gdk0/mnt/scratch/lts2/nallapar/rb-prof/data/Jan_2024/Lina/Test_Final_LXG_DSP.h5'\n",
    "\n",
    "distance_thresh = 100 # for the global attribution average plot\n",
    "attr_segment_length = 20 # num codons on each side\n",
    "\n",
    "# load h5\n",
    "int_ds = h5py.File(filename, 'r')\n",
    "int_ds.keys()\n",
    "\n",
    "id_to_codon = {idx:''.join(el) for idx, el in enumerate(itertools.product(['A', 'T', 'C', 'G'], repeat=3))}\n",
    "codon_to_id = {v:k for k,v in id_to_codon.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dataframe\n",
    "distance_from_A_site = []\n",
    "attribution_value = []\n",
    "codon_id = []\n",
    "\n",
    "len_samples = len(int_ds['node_attr'])\n",
    "\n",
    "for i in tqdm(range(len_samples)):\n",
    "    node_attr_sample = int_ds['node_attr'][i]\n",
    "    x_input_sample = int_ds['x_input'][i]\n",
    "    # # take absolute value\n",
    "    # node_attr_sample = np.abs(node_attr_sample)\n",
    "    # num codons is square root of length of node_attr_sample\n",
    "    num_codons = int(len(node_attr_sample)**0.5) \n",
    "    # convert to 2D array of shape (num_codons, num_codons)\n",
    "    node_attr_sample = node_attr_sample.reshape(num_codons, num_codons)\n",
    "    # remove virtual node codon\n",
    "    node_attr_sample = node_attr_sample[:-1, :-1]\n",
    "\n",
    "    # iterate over each row\n",
    "    for j in range(num_codons-1):\n",
    "        # iterate over each column\n",
    "        # normalize this row by dividing by the max value\n",
    "        node_attr_sample[j] = node_attr_sample[j] / np.sum(np.abs(node_attr_sample[j]))\n",
    "        for k in range(num_codons-1):\n",
    "            # add to the dataframe\n",
    "            if abs(j-k) <= distance_thresh:\n",
    "                distance_from_A_site.append(j-k)\n",
    "                attribution_value.append(node_attr_sample[j][k])\n",
    "                codon_id.append(id_to_codon[x_input_sample[k]])\n",
    "\n",
    "# # make a dict\n",
    "data = {'Offset from A site (codons)': distance_from_A_site, 'Attribution': attribution_value, 'Codon': codon_id}\n",
    "\n",
    "# make a dataframe\n",
    "df_distance_attr = pd.DataFrame(data)\n",
    "df_distance_attr.to_pickle('final_plots/df_distance_attr.pkl.zip', compression='zip')\n",
    "\n",
    "# df_distance_attr = pd.read_pickle('final_plots/df_distance_attr.pkl.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a bar plot for ds_attr_dist from distance -100 to +100\n",
    "# group by and mean atribution\n",
    "# remove codon column\n",
    "df_distance_attr_full = df_distance_attr.drop('Codon', axis=1)\n",
    "# make atribution values absolute\n",
    "df_distance_attr_full['Attribution'] = np.abs(df_distance_attr_full['Attribution'])\n",
    "\n",
    "# group by and mean\n",
    "# df_distance_attr_full = df_distance_attr_full.groupby('Offset from A site (codons)', as_index=False)['Attribution'].mean()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "b = sns.lineplot(x='Offset from A site (codons)', y='Attribution', data=df_distance_attr_full, color='#e74c3c', ci='sd')\n",
    "# change font style to sans-serif\n",
    "# plt.xlim(-100, 100)\n",
    "b.axes.set_title(\"Contribution of positions in the global neighborhood of the A site\", fontsize=15, fontname='sans-serif')\n",
    "b.set_xlabel(\"Offset from A site (codons)\", fontsize=15, fontname='sans-serif')\n",
    "b.set_ylabel(\"Attribution\", fontsize=15, fontname='sans-serif')\n",
    "plt.axvline(x=0, color='black', linestyle='--')\n",
    "\n",
    "plt.savefig('final_plots/offset_attr_global.svg')\n",
    "plt.savefig('final_plots/offset_attr_global.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a bar plot for ds_attr_dist from distance -10 to +10\n",
    "df_distance_attr_local = df_distance_attr[df_distance_attr['Offset from A site (codons)'].between(-10, 10)]\n",
    "# make atribution values absolute\n",
    "df_distance_attr_local['Attribution'] = np.abs(df_distance_attr_local['Attribution'])\n",
    "plt.figure(figsize=(10, 6))\n",
    "b = sns.barplot(x='Offset from A site (codons)', y='Attribution', data=df_distance_attr_local, color='#e74c3c')\n",
    "# change font style to sans-serif\n",
    "b.axes.set_title(\"Contribution of positions in the local neighborhood of the A site\", fontsize=15, fontname='sans-serif')\n",
    "b.set_xlabel(\"Offset from A site (codons)\", fontsize=15, fontname='sans-serif')\n",
    "b.set_ylabel(\"Attribution\", fontsize=15, fontname='sans-serif')\n",
    "plt.xticks(range(0, 21), ['-10', '-9', '-8', '-7', '-6', '-5', '-4', '-3', 'E', 'P', 'A', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10'])\n",
    "\n",
    "plt.savefig('final_plots/offset_attr_local.svg')\n",
    "plt.savefig('final_plots/offset_attr_local.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_distance_attr_codon = df_distance_attr[df_distance_attr['Offset from A site (codons)'].between(-5, 5)] \n",
    "# codon to int dictionary\n",
    "codon_to_id_plot = {\n",
    "    'GCG': 0,\n",
    "    'GCA': 1,\n",
    "    'GCC': 2,\n",
    "    'GCT': 3,\n",
    "    'TGT': 4,\n",
    "    'TGC': 5,\n",
    "    'GAC': 6,\n",
    "    'GAT': 7,\n",
    "    'GAG': 8,\n",
    "    'GAA': 9,\n",
    "    'TTT': 10,\n",
    "    'TTC': 11,\n",
    "    'GGC': 12,\n",
    "    'GGT': 13,\n",
    "    'GGA': 14,\n",
    "    'GGG': 15,\n",
    "    'CAT': 16,\n",
    "    'CAC': 17,\n",
    "    'ATC': 18,\n",
    "    'ATA': 19,\n",
    "    'ATT': 20,\n",
    "    'AAG': 21,\n",
    "    'AAA': 22,\n",
    "    'TTA': 23,\n",
    "    'TTG': 24,\n",
    "    'CTT': 25,\n",
    "    'CTA': 26,\n",
    "    'CTC': 27,\n",
    "    'CTG': 28,\n",
    "    'ATG': 29,\n",
    "    'AAC': 30,\n",
    "    'AAT': 31,\n",
    "    'CCT': 32,\n",
    "    'CCC': 33,\n",
    "    'CCA': 34,\n",
    "    'CCG': 35,\n",
    "    'CAG': 36,\n",
    "    'CAA': 37,\n",
    "    'CGG': 38,\n",
    "    'AGA': 39,\n",
    "    'CGA': 40,\n",
    "    'AGG': 41,\n",
    "    'CGC': 42,\n",
    "    'CGT': 43,\n",
    "    'TCT': 44,\n",
    "    'TCC': 45,\n",
    "    'TCA': 46,\n",
    "    'TCG': 47,\n",
    "    'AGT': 48,\n",
    "    'AGC': 49,\n",
    "    'ACT': 50,\n",
    "    'ACG': 51,\n",
    "    'ACC': 52,\n",
    "    'ACA': 53,\n",
    "    'GTA': 54,\n",
    "    'GTC': 55,\n",
    "    'GTT': 56,\n",
    "    'GTG': 57,\n",
    "    'TGG': 58,\n",
    "    'TAC': 59,\n",
    "    'TAT': 60,\n",
    "    'TAA': 61,\n",
    "    'TGA': 62,\n",
    "    'TAG': 63\n",
    "}\n",
    "\n",
    "id_to_codon_plot = {v:k for k,v in codon_to_id_plot.items()}\n",
    "\n",
    "# convert codon to int\n",
    "codon_list = list(df_distance_attr_codon['Codon'])\n",
    "codonintlist = []\n",
    "for codon in codon_list:\n",
    "    codonintlist.append(codon_to_id_plot[codon])\n",
    "df_distance_attr_codon['CodonInt'] = codonintlist\n",
    "\n",
    "# make a heatmap with seaborn, with the mean attribution for each codon at each position    \n",
    "df_distance_attr_codon = df_distance_attr_codon.groupby(['Offset from A site (codons)', 'CodonInt'])['Attribution'].mean().reset_index()\n",
    "# make a table 15 x 64 with the mean attribution for each codon at each position\n",
    "df_table = df_distance_attr_codon.pivot(index='Offset from A site (codons)', columns='CodonInt', values='Attribution')\n",
    "\n",
    "plt.figure(figsize=(40, 10))\n",
    "# make a heatmap with seaborn using the table\n",
    "# cmap negative with red, positive with blue\n",
    "# print full df_table\n",
    "# save df table\n",
    "df_table.to_csv('final_plots/codon_attr_table.csv')\n",
    "# impute nans to 0\n",
    "df_table = df_table.fillna(0)\n",
    "# invert the y axis\n",
    "df_table = df_table.iloc[::-1]\n",
    "\n",
    "# remove last three rows\n",
    "df_table = df_table.iloc[:,:-3]\n",
    "\n",
    "ax = sns.heatmap(df_table, cmap='coolwarm', center=0, cbar_kws={'label': ''}, square=True, annot_kws={\"size\": 40})\n",
    "ax.figure.axes[-1].yaxis.label.set_size(40)\n",
    "cbar = ax.collections[0].colorbar\n",
    "# here set the labelsize by 20\n",
    "cbar.ax.tick_params(labelsize=25)\n",
    "plt.xlabel('', fontsize=40)\n",
    "plt.ylabel('Offset from A site (codons)', fontsize=40)\n",
    "plt.title('Contribution of codons in different positions around the A site', fontsize=40)\n",
    "\n",
    "# flip y axis\n",
    "# change y axis \n",
    "plt.yticks(range(0, 11), ['5', '4', '3', '2', '1', 'A', 'P', 'E', '-3', '-4', '-5'], fontsize=30, va='top', rotation=0)\n",
    "\n",
    "codon_to_aa = {\n",
    "        'ATA':'I', 'ATC':'I', 'ATT':'I', 'ATG':'M',\n",
    "        'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T',\n",
    "        'AAC':'N', 'AAT':'N', 'AAA':'K', 'AAG':'K',\n",
    "        'AGC':'S', 'AGT':'S', 'AGA':'R', 'AGG':'R',                \n",
    "        'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L',\n",
    "        'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P',\n",
    "        'CAC':'H', 'CAT':'H', 'CAA':'Q', 'CAG':'Q',\n",
    "        'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R',\n",
    "        'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V',\n",
    "        'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A',\n",
    "        'GAC':'D', 'GAT':'D', 'GAA':'E', 'GAG':'E',\n",
    "        'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G',\n",
    "        'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S',\n",
    "        'TTC':'F', 'TTT':'F', 'TTA':'L', 'TTG':'L',\n",
    "        'TAC':'Y', 'TAT':'Y', 'TAA':'_', 'TAG':'_',\n",
    "        'TGC':'C', 'TGT':'C', 'TGA':'_', 'TGG':'W',\n",
    "        'NNG':'R', 'NNC':'T', 'NGT':'S', 'NGA':'R',\n",
    "        'NNT':'Y', 'NGC':'S'\n",
    "    }\n",
    "\n",
    "# group codons by amino acid and order the x ticks\n",
    "aa_list = []\n",
    "codon_list = []\n",
    "for i in range(61):\n",
    "    aa_list.append(codon_to_aa[id_to_codon_plot[i]])\n",
    "    codon_list.append(id_to_codon_plot[i])\n",
    "\n",
    "plt.xticks(range(0, 61), codon_list, rotation=90, fontsize=30, ha='left')\n",
    "\n",
    "plt.savefig('final_plots/distance_vs_attribution_heatmapCodon.png')\n",
    "plt.savefig('final_plots/distance_vs_attribution_heatmapCodon.svg')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make a list of lists with attr_segments centered around the A site\n",
    "# attr_segment_lists = []\n",
    "\n",
    "# for i in tqdm(range(len_samples)):\n",
    "#     node_attr_sample = int_ds['node_attr'][i]\n",
    "#     # take absolute value\n",
    "#     node_attr_sample = np.abs(node_attr_sample)\n",
    "#     # num codons is square root of length of node_attr_sample\n",
    "#     num_codons = int(len(node_attr_sample)**0.5)\n",
    "#     # convert to 2D array of shape (num_codons, num_codons)\n",
    "#     node_attr_sample = node_attr_sample.reshape(num_codons, num_codons)\n",
    "#     # iterate over each row\n",
    "#     for j in range(attr_segment_length, num_codons-attr_segment_length-1):\n",
    "#         # iterate over each column\n",
    "#         # normalize this row by dividing by the max value\n",
    "#         node_attr_sample[j] = node_attr_sample[j] / np.max(node_attr_sample[j])\n",
    "#         # add to the segment list \n",
    "#         attr_segment = node_attr_sample[j][j-attr_segment_length:j+attr_segment_length+1]\n",
    "\n",
    "#         assert len(attr_segment) == (2*attr_segment_length + 1)\n",
    "\n",
    "#         attr_sample_dict = {'attr_segment': attr_segment, 'sample_id': i, 'codon_id': j, 'transcript': int_ds['transcript'][i]}\n",
    "\n",
    "#         attr_segment_lists.append(attr_sample_dict)\n",
    "\n",
    "# print(\"Number of Attr Segments: \", len(attr_segment_lists))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # np.random.shuffle(attr_segment_lists)\n",
    "# attr_segment_lists = np.array(attr_segment_lists)\n",
    "\n",
    "# # construct a dendrogram of the segments using hclust \n",
    "# only_segments = []\n",
    "# for i in range(len(attr_segment_lists)):\n",
    "#     only_segments.append(attr_segment_lists[i]['attr_segment'])\n",
    "# distances_attr = pdist(only_segments, metric='euclidean')\n",
    "# print(\"Made distance wise matrix for the segments\")\n",
    "# Z = linkage(distances_attr, method='complete')\n",
    "\n",
    "# # plot the dendrogram for this and color them according to the clusters that are generated\n",
    "# plt.figure(figsize=(25, 10))\n",
    "# plt.title('Hierarchical Clustering Dendrogram')\n",
    "# plt.xlabel('sample index')\n",
    "# plt.ylabel('distance')\n",
    "# dendrogram(Z, leaf_rotation=90., leaf_font_size=8.)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get clusters from Z\n",
    "# clusters = fcluster(Z, t=2.5, criterion='distance')\n",
    "\n",
    "# print(\"Number of Clusters: \", len(set(clusters)))\n",
    "\n",
    "# np.unique(clusters,\n",
    "#           return_counts=True)\n",
    "# # sort in descending order of cluster size\n",
    "# cluster_size = np.unique(clusters, return_counts=True)\n",
    "# print(np.flip(np.argsort(cluster_size[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make plots for each of the clusters, with their averaged segment\n",
    "# for i in np.flip(np.argsort(cluster_size[1])):\n",
    "#     cluster_indices = np.where(clusters == i+1)[0]\n",
    "#     if len(cluster_indices) < 50:\n",
    "#         continue\n",
    "#     print(\"Cluster: \", i)\n",
    "#     print(\"Number of segments: \", len(cluster_indices))\n",
    "#     cluster_segments = attr_segment_lists[cluster_indices]\n",
    "#     cluster_segments = np.mean(cluster_segments, axis=0)\n",
    "#     sns.barplot(x=range(-10, 10), y=cluster_segments, color='#e74c3c')\n",
    "#     plt.show()\n",
    "#     print(\"----------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # construct a dendrogram of the segments using hclust \n",
    "# only_segments = []\n",
    "# for i in range(len(attr_segment_lists)):\n",
    "#     only_segments.append(attr_segment_lists[i]['attr_segment'])\n",
    "# distances_attr = pdist(only_segments, metric='euclidean')\n",
    "# print(\"Made distance wise matrix for the segments\")\n",
    "# Z = linkage(distances_attr, method='ward')\n",
    "\n",
    "# # plot the dendrogram for this and color them according to the clusters that are generated\n",
    "# plt.figure(figsize=(25, 10))\n",
    "# plt.title('Hierarchical Clustering Dendrogram')\n",
    "# plt.xlabel('sample index')\n",
    "# plt.ylabel('distance')\n",
    "# dendrogram(Z, leaf_rotation=90., leaf_font_size=8.)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get clusters from Z\n",
    "# clusters = fcluster(Z, t=12, criterion='distance')\n",
    "\n",
    "# print(\"Number of Clusters: \", len(set(clusters)))\n",
    "\n",
    "# np.unique(clusters,\n",
    "#           return_counts=True)\n",
    "# # sort in descending order of cluster size\n",
    "# cluster_size = np.unique(clusters, return_counts=True)\n",
    "# # print(np.flip(np.argsort(cluster_size[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make plots for each of the clusters, with their averaged segment\n",
    "# for i in np.flip(np.argsort(cluster_size[1])):\n",
    "#     cluster_indices = np.where(clusters == i+1)[0]\n",
    "#     # if len(cluster_indices) < 50:\n",
    "#     #     continue\n",
    "#     print(\"Cluster: \", i)\n",
    "#     print(\"Number of segments: \", len(cluster_indices))\n",
    "#     # get all the cluster segments\n",
    "#     cluster_segments = []\n",
    "#     for j in cluster_indices:\n",
    "#         cluster_segments.append(only_segments[j])\n",
    "#     cluster_segments = np.mean(cluster_segments, axis=0)\n",
    "#     sns.barplot(x=range(-attr_segment_length, attr_segment_length+1), y=cluster_segments, color='#e74c3c')\n",
    "#     plt.show()\n",
    "#     print(\"----------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "riboclette",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
